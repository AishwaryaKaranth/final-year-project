## Abstract
To understand the large-scale structure of the universe, studying the morphology of galaxies is imperative. Scientists build a deeper understanding of the formation and evolution of galaxies by classifying them into different categories based on morphological parameters. With evolving galaxies and growing galaxy image data it was impossible for manual sorting. Automated means were then considered and newer algorithms evolved for feature extraction, reduction and classification. In this paper, we present a survey of 20 research efforts that employ various machine learning and deep learning techniques for the classification of galaxies based on morphology to gather insights into the accuracy that is obtained by these approaches. The pre-processing methods used on the data, models employed and the overall performance achieved according to the metrics used in each work under study are examined in this paper.

## Introduction

13.8 billion years ago, the Big Bang led to the creation of the universe that we know today, comprising of billions of galaxies of sundry sizes and shapes. Galaxies are gravitationally bound collections of interstellar dust, gas and stars and these mysterious creations are a fundamental topic in cosmology. Galaxies exhibit a plethora of different morphologies and knowledge of the same aids astrophysicists to test existing theories pertaining to the nature of the universe and construct conjectures of their own. Previously, astronomers would use manual techniques for the purpose of classification of galaxies but with the advent of epochal fields like Machine learning and Deep learning, this process has since been automated, which not only greatly reduces the time consumed but also prevents misclassifications and inaccuracies that are inevitable in manual methods. There has been an explosion in the astronomical data available in recent times and the manual analysis of the same is not feasible. Morphological classification of galaxies is the process of categorising galaxies based on their visual shapes. The work surveyed in this paper exhibits different styles of classification. In [1], [6] and [8], there was a three-category classification - elliptical, spiral and irregular. In [2], they attempted a five-category classification - spiral, elliptical, round, disk and other. In [3], they tried a three-category classification - elliptical, spiral and irregular initially and then did a 7-category classification based on the Hubble scheme. Another attempt [4] made use of the Galaxy Decision Tree (Willett et al., 2013) in which there are 11 questions and they have to predict the probabilities of 37 answers. In [5], the authors discuss the importance of Shape descriptors that could be useful indicators in classifying galaxies. The motivation for presenting this survey stems from the need to find the most optimal, efficient and accurate existing method for the classification of galaxies based on morphology. In [7], two distinct approaches for galaxy morphology classification are proposed - one based on non-parametric morphology and traditional Machine learning algorithms and another based on Deep learning, and these were used to perform a three-class classification - spiral, elliptical, barred spiral. In [9], the categories of classification were 5 classes - completely round, smooth, in-between smooth, cigar-shaped smooth, edge-on and spiral. In [10], reliable models were used to distinguish between spiral galaxies, elliptical galaxies and star/unknown galactic objects. The Sloan Digital Sky Survey ,is one of the prominent sky surveys and comprises of deep, multi-color images covering more than a quarter of the sky and created 3-dimensional maps containing more than 930,000 galaxies and more than 120,000 quasars [13]. The Galaxy Zoo 2 project involved a crowdsourcing effort via a web based platform to classify the galaxies as per a catalogue containing 11 questions and 37 different possible responses in all. In [11], they eliminated certain questions from the catalogue such as number and tightness of spiral arms. Deep Learning is said to extract the most relevant features automatically using non-linear transformations. In [12], Self-supervised learning technique works on unlabelled data with certain attributes that can be derived from the images. In [16], classification is done by considering 13 galaxy parameters measured by machine (ESO-LV) into five types (E, S0, Sa+Sb, Sc+Sd and Irr). In [19], they have classified the images of radio galaxies based on morphology. They have considered the case of Fanaroff-Riley (FR) class of radio galaxies and bent-tailed morphology. In [20], Hubble's classification scheme is used to classify the galaxies. 

Our motivation for this paper was to find approaches to the galaxy classification problem with good performances to aid further research. We collected papers, filtered out 20 of them and analysed each paper based on the following questions -
What were the sources of the data being used?
What were the classes/ labels being considered?
What were the preprocessing and data augmentation techniques being employed to enhance the image data?
What was the method (ML/DL models) being used for the classification process?
What was the overall performance of their model?
What could be the reasons for the performance not being better and what are the suggestions for improvement?

## Design Methodologies
  ### Datatsets
  In this subsection, we introduce the sources of data made use of in all the related works surveyed. There are numerous large datasets available containing thousands of images of galaxies. Most of the datasets contain galaxies imaged by the Sloan Digital Sky Survey (SDSS).
  
  
In [1], an attempt was made to manually collected their images from Google using a browser extension called Fatkun Batch Image Download which led them to do a significant amount of pre-processing, discussed in the following subsection. Some of this pre-processing could be avoided by using datasets like the one by Galaxy Zoo. The current Galaxy Zoo combines images from the SDSS with the most distant images yet from Hubble's CANDELS project. The GZ data has fuelled multiple papers. The GZ data comes with 61578 pre-classified 424 × 424 RGB images of galaxies taken from SDSS. It also comes with the classifications that have been collected from a crowdsourced quiz which are given in the form of probabilities of the answers to 37 questions. This dataset was used in [2] and [4]. In [3], a dataset obtained from Zsolt Frei’s galaxy catalogue was used. Hubble Tuning Fork images were used as model or prototype images in [5].
In [6],Sloan Digital Sky Survey (SDSS) Data set was used. In [7],the main dataset was employed from Sloan Digital Sky Survey Data Release 7 (SDSS-DR7) and Galaxy Zoo catalogues with 670,560 galaxies for measuring morphology and training the classification models. In [8],The dataset used was taken from the EFIGI catalogue This catalogue dataset consists of more than 11,000 images and contains samples from different Hubble types galaxies. This catalogue also combines the data from standard surveys and catalogues of Sloan Digital Sky Survey, Value-Added Galaxy Catalogue, Principal Galaxy Catalogue. In [9],The galaxy images in this are drawn from the galaxy zoo which contains 61578 JPG colour galaxy images where each image is 424x424x3 pixels in size with probability that each galaxy is is classified into different morphologies. In [10],full sample sets of Galaxy images from SDSS DR7 was used. The dataset consists of 667,935 entries each of which corresponds to an object in the SDSS database. After some sort of filtering, the dataset was reduced to 251,867.
[11] uses Galaxy Zoo 2 and Nair et al. catalogues 2010 for training .For testing the catalogues used were Huertas-Company et al. 2011 and Cheng et al. 2011 catalogues. Southern Photometric Local Universe Survey (S-PLUS) is an imaging survey that southern sky, it uses 12 optical bands. [12] uses the first release of the S-PLUS which includes both images and catalogues of detected objects and the labels for this dataset is obtained by matching the astronomical coordinates from S-PLUS to SDSS spectra catalogue
[13] uses Galaxy Zoo 2 catalog and datasets derived from Catalog Archive Server of SDSS(Sloan Digital Sky Survey) where the image size was 120x120 px. An approximate of 2,45,609 images were used[13].Zsolt frei Catalog comprises of nearly 113 images from nearby galaxies taken in multiple pass bands the images had high resolution and had better calibrations therefore extensive pre-processing was not required[14].



  ### Preprocessing
  This Subsection introduces differnt processing techniques used to enhance desired features present in an image  which are relevant for further analysis.Image processing is very essential to analyze and make important inferences about celestial objects.It plays a vital role in analyzing and interpreting galaxy images to improve and analyze the properties of celestial objects.Some image processing steps were involved before feeding the image data into the models. This is done to improve 
the image data and suppress the undesired distortions.

In [1], Image processing played a vital role in [1] as their work was focused on comparing the performance of the classifier with and without using image processing techniques. They had to resize their images as the data was collected from Google with varying sizes. The different image processing methods using which they tested their classifier were Canny Edge detection, Histogram Equalization, and Median Filtering.In [2], they began with cropping their images to remove secondary objects and rotating them to make the principal axes vertical, following which they performed background subtraction Since there were a large number of features, to make their model less computationally intensive and reduce overfitting,Principal Component Analysis was performed to reduce the number of features while also not allowing the loss of a lot of galactic information.
In the image processing phase of [3], they scaled, rotated, cropped and centered the images. In the Feature Extraction phase they measured 6 morphic features for each image which were based on visual characteristics and also generated PCA features for each image. In [4], they focused on studying the importance of scale in the process of Galaxy Image Classification. They performed random rotation, horizontal and vertical flipping and shifting for the purpose of Data Augmentation. They pre-processed the images to have three different scales - a normalized scale such that the whole galaxy is shown in the image, 6464 and 256256 and proceeded with determining which scale would produce better results. [5] discusses the importance of Shape descriptors that could be useful indicators in classifying galaxy shapes. The performed thresholding using Otsu’s method, morphological opening operation and flood-fill operation to fill the holes on the images in the preprocessing stageIn [6],they focussed on preprocessing techniques like Histogram Equalization,contrast Stretching and Noise filtering which is very helpful in Feature Extraction,image analysis and image display. Image augmentation techniques were applied to the training data and included the rotation, reflection, cropping and Gaussian noise.As a result Of image augmentation overfitting was avoided.In [7],Multilayer Perceptron models were used to classify galaxies considering different numbers of classes.multiple layers of non-linear transformations were used In [8],Image augmentation techniques were applied to the training data and included rotation, reflection, cropping andGaussian noise. These techniques decreased the overfitting problem of the proposed architecture. For preprocessing in [9],They cropped the image in the range of [170,240]at first step,which allowed all the main information to be contained in the center of image, also eliminates many noises like other secondary objects Then, the image is resized to 80x80x3 pixels, which is just dimension reduction then Next the image is randomly rotated with 0,90,180,270 degree because of rotation invariant of galaxy images and randomly horizontally flipped.Brightness, contrast, saturation and hue adjustment were applied to the image and the last step is image whitening.In [10],independent component analysis was performed to determine the most significant components which is necessary for classification.

Image Resizing:The images used might be of different sizes ,while building models it is often required that all the images have a fixed size,therefore resizing images are carried out before training[14].The images are downsampled to (49x49x3) as it reduced the computation time on each image[11].Initially coloured image is converted to a grey scale image where the pixel intensities varies from 0-255. A binary image has only two pixel values[15] Otsu transform is one of the image binarizing technique which involves an iterative process which separates the foreground and background pixels[13] [15] Data Augmentation : is a form of artificially expanding the dataset.It trains the model on a variety of images thereby allowing it to generalize well.Certain manipulations on the images includes rotating [14][11],flipping the images horizontally and vertically[11],zooming the images in and out[11],shifting -horizontal or vertical shifts,centering[14] 
In [17], They first generated images that are independent of orientation and scale and then used principal component analysis for a more compact representation of images. [18] presents various methods in which astronomy images can be processed. According to [18], linear filters remove noise efficiently but there is a trade-off that is the texture of the image is not preserved which is why non-filters are used. The non-linear filter used in [18] is non-local means filter. Non-local means filter replaces the intensity value of the target pixel with an average of a selection of intensities of other pixels where small regions centered on other pixel is compared to the region having the target pixel as its center, averaging here is performed when both the regions have a high rate of similarity and therefore the texture and details are preserved. Object segmentation is crucial in image processing as astronomical telescopes often capture overlapping celestial objects. Chan Vese algorithm is used for segmentation[18]. Segmentation algorithm is used for segmenting objects lacking distinct boundaries. Watershed algorithm is a segmentation algorithm used to plot the representation of distance mapping between galaxies in [18]. To prevent diffusions across high gradients, Random Walker algorithm is used[18]. In Random Walker algorithm, anisotropic diffusion equation is solved using the labels initiated at the markers' positions where the local diffusivity coefficient is greater if neighboring pixels have similar intensity values which prevents diffusion across high gradients. Watershed algorithm is a segmentation algorithm used to plot the representation of distance mapping between galaxies in [18]. For preprocessing in [20], alpha-rooting transform, heap transform and Paired (Grigoryan) Transform are used. For galaxy detection, background subtraction and nonlinear filtering is applied to segment the galaxies. Edge detection is performed to provide a perimeter pixel of the galaxies[20]. In [16], they found that filtering the images galaxies in the training set improved the classification.

  
  ### Models
  The goal of this sub-section is to provide insight into the techniques, architectures and models that we encountered in the papers surveyed in this work. Many algorithms of Machine learning and Deep learning have been used. Machine learning is a field of research that deals with learning algorithms used to parse and learn from data and make predictions based on the same. Deep Learning is a subfield of machine learning concerned with algorithms that create artificial neural networks to make decisions. Convolutional Neural Networks are a type of deep neural networks which are extensively used for image recognition and classification.
  <br>
Feature extraction: WND-CHRM is an image analysis technique originally designed for biological it works by extracting large volumes of image feature descriptors [13] used the technique and different feature descriptor is required for identifying unique features and around 2883 features were reduced by means of a Fischer score that was set to a certain acceptable score. Classification was performed using the Weighted Nearest Neighbour scheme considering the Fischer scores as weights. For each question from the catalogue samples were divided into training and test set making sure that the number of samples for each class remains equal. 
<br>
Non-negative matrix factorization is a dimensionality reduction technique where the given matrix can be expressed as the product of two other matrices, the basis matrix comprising of the image features and the coefficient matrix. In [14] both the test and training samples are normalized. While training the basis matrix(W) and the coefficient matrix (B) are adjusted such that their product gives the original database vector (V) considering the Euclidean norm to reduce the distance. For testing the test set S is represented by product of coefficient A and W matrices. The label will be the maximum coefficient value of A. 
<br>
[15] extracted different features from binary images such as detecting the circularity , finding the view angles, determining the existence of bulge, detecting the tightness and number of spiral arms. A knowledge base is constructed with CBH (Case Based Reasoning) constructed from human-annotated data .CBCVH builds on extracted feature from images comprised of numerical value for each feature. RBCVF rule based system constructed from the extracted features, which comprised of two parts first the feature of the subclass, second the next rule that must be fired. [15] the first three features weights are assigned to each feature considering how close the new cases should be to the training cases, for the last 3 features the minimum value for a feature from the new case and all cases in the knowledge base. [12]Self supervised learning involves extracting attributes easily extractable from the data in pretext task and use those for downstream tasks. Source Extractor is a program to build catalogue of objects of astronomical images.
<br>
In [5] after the Elliptic Fourier Descriptors were obtained and Principal Component Analysis was performed on the EFDs, the Euclidean distance between a particular candidate image and all the model images was calculated. The average distance was computed and the minimum value was considered as the best match.
<br>
In [17], the classification of galaxies based on morphology is done using three different machine learning algorithms on three, five, and seven galaxy types. The Hubble tuning fork scheme was used to classify the galaxies as spiral, elliptical and irregular. The machine learning algorithms used were Naive Bayes, rule-induction algorithm C4.5, and random forest. In the ensemble method used here where an ensemble consists of a set of classifiers whose individual decisions are in a certain way usually by voting to classify new examples. The ensemble method used here is bagging. 
<br>
In [2], they performed classification using SVM with an RBF kernel, decision tree, random forest, AdaBoost classifier, and KNN. They decided to proceed with regression by predicting the probability density function of the classification, to account for uncertain classifications. They also applied three clustering algorithms to the PCA dataset - k-means clustering, Agglomerative clustering with complete linkage and ward linkage. 
<br>
In [3], they trained SVM with RBF kernel, Random Forest, Naive Bayes classifiers and their AdaBoosted versions on the training subsets. They implemented 10-fold cross validation (3 times) on the training set while recalculating the PC vector basis each time and reported the average of these 3 runs as their overall accuracy and standard deviation for each algorithm. For each algorithm, they classified the galaxies into 3 and 7 classes using only morphic features, only PCA features, and both morphic and PCA features.
<br>
In [10], reliable machine learning models were used to distinguish between spiral galaxies, elliptical galaxies, or star/unknown galactic objects. Decision tree learning algorithms and fuzzy inferencing systems were applied and Random Forest a classifier in which a number of decision trees were built. When processing a particular sample, the output by each of the individual trees is considered and the resulting node was taken as the final classification.
<br>
In [20], the classification of galaxies was separated into two parts, (1) ellipticals and spirals and (2) simple spirals and barred spirals. Sparse representation of data was considered where sparse representation decomposition is achieved by optimizing an objective function that includes both a reconstructive and a discriminative term. The goal of the data decomposition is to achieve the sparsest representation, that is few coefficients have a large magnitude, while most of them are close to zero. For the first part, 6 features were used for training, and for the second part, only the asymmetry index was trained.  
<br>
In [16], the classification of galaxies is done by an artificial neural network algorithm. The neural network is here behaves as a Bayesian classifier. Backpropagation algorithm is used to train a network on part of the catalog, and then using the measured parameters, predict the classification for the rest of the catalog. They considered five types(E, S0, Sb, Sc+Sd and Irr) of galaxies with 13 parameters. Bayesian classifier here assigns a posterior probability to five classes considered. The threshold activation function used here was the sigmoid function. Weights were determined by minimizing least-squares which was done in backpropagation using gradient descent. The learning rate and momentum were constant. A total of 1.5M iterations were done.
<br>
In [18], the radio galaxies are classified based on morphology using convolutional neural networks(CNN). It considers Fanaroff-Riley(FR) class of radio galaxy and bent-tailed morphology. CNNs classified images of the FRI and FRII and bent-tailed radio galaxies with high accuracy. 
<br>
In [8], Deep learning approaches were used for performing classification. The Hubble galaxy classification scheme was used to classify the galaxies as spiral, elliptical and irregular. The CNN uses two layers such as convolutional layer and pooling layer. The input of any convolutional layer was an image, and the outputs are feature maps that are convolved with a set of weights(filters) and non-linearities (ReLU) which is applied to the weighted sum of these convolutions in order to produce a feature map. The optimization technique used was Gradient Descent that updates all the weights at once after running through all the samples in the training dataset once Back Propagation Algorithm was used here to train the network then predict the classification output.
<br>
In [1], a deep convolutional neural network called Inception module was utilised with a global average pooling replacing the fully connected layer to reduce the number of parameters thereby reducing the computation requirements. They passed the images processed by the three methods described in the previous section, along with their unprocessed equivalents to compare the classifier’s performance. 
<br>
In [4], CNNs were used with 9 convolutional layers and 3 pooling layers in the convolution segment, followed by dropout (with a dropout rate of 50%) and maxout layers without which they claim the training would be a problem due to overfitting. One neural network was trained to predict the probability of each of the 37 answers of the decision tree.
<br>
In [5] after the Elliptic Fourier Descriptors were obtained and Principal Component Analysis was performed on the EFDs, the Euclidean distance between a particular candidate image and all the model images was calculated. The average distance was computed and the minimum value was considered as the best match. [11] used Cnn with Keras library. had 4 convolutional layers, drop out to avoid overfitting, max pool layers. For GZ2 catalog model was trained on a binary classification model for each question (disk/flat, edge-on, bulge prominence, roundness, merger). Agreement parameter was devised to specify the consistency for classification. A T-Type model trained on N10 catalog assigned an integer to each galaxy,(-3 to 10) and used mean squared error (mse)for loss.The transitions of types from E to spiral morphology is observed.E11 and S0 are further separated using pre trained weights from previous process,barred galaxies are further separated as strong,intermediate weak N10 bars using weights from GZ2 model. 
<br>
[12] Used Source Extractor to obtain magnitude values from images. They scaled them by dividing the values by 30 and used them as targets for prediction as a part of the pretext task. 
In [12] VGG-16 architecture yielded better result both with pretrained on ImageNet weights and training from scratch .2048 unit fully connected layer with dropout of 0.5 was used. For classification task output was passed through softmax and loss function set to categorical cross-entropy, for regression task the modified relu , Mean absolute error was used. In the pre-text task SGD with a learning rate of 10-3 was used. Feature extraction and finetuning were done freezing some layers and training the remaining. 
<br>
In [9], A variant of residual networks (ResNets) for galaxy morphology classification was proposed here. Here galaxies were classified into 5 classes namely completely round smooth, in-between smooth, cigar-shaped smooth,edge-on, and spiral. Artificial Neural Networks and convolutional neural networks (CNNs) especially residual networks (ResNets) was introduced where By visualizing filters weights and feature maps the first layer filters detect the different galaxy edges, corners, etc. from the original pixel, then use the edge to detect simple shapes in second layer filters, such as the bar and the elliptical, and next use these shapes to detect more advanced features in high level layer filters. Also, different filters also learn different color information, mainly red and blue, which might correspond to the color of galaxies themselves, such as red elliptical galaxy and a blue spiral galaxy. 
<br>
In [6], Morphological Galaxy Classification was done using Machine Learning Algorithms And image analysis method where feed forward neural network and locally weighted regression methods were used for performing classification task to classify the galaxy into three categories namely Elliptical, Spiral, Irregular. The raw data images were used as input without any expert knowledge in feature designing or optimization of segmentation parameters. For Feature Extraction architecture convolutional layer was proposed where feature detectors were used which basically serves as neural network filters and two principles fully connected layers for the classification.Relu activation function(non linear activation function) was used as it simplify computation.
In [7],Here two distinct approaches were used for performing classification.one based on non-parametric morphology and traditional machine learning algorithms; and another based on Deep Learning.Decision Tree Among the different versions and variations of DTs,the optimized version of Classification and Regression Tree (CART) algorithm Support Vector Machines(SVM) was used. Deep Learning (DL) methods were built through a deep neural network with multiple layers of non-linear transformations.They Also performed Two class(Elliptical and spiral) and three class classification(Elliptical,Spiral,Irregular) task.deep convolutional neural network (CNN) GoogLeNet Inception, to obtain morphological classifications for galaxies forall galaxies in the main catalog With the twenty-two layer network.





  
## Results
This section discusses the performance of the different models utilised in the works surveyed. Regarding the methods used to evaluate the performance, various metrics have been employed by the authors. In [1], the best results were seen for unprocessed images. The processing techniques could have meddled with the image quality and led to the loss of some important features. Out of the three processing techniques, histogram equalization showed the best results and Canny edge performed the worst. The results were taken for different numbers of epochs with the average accuracies for all the methods being - 74.2% for unprocessed images, 57.2% using histogram equalization, 56.3% using median filtering and 53.1% using Canny edge detection. The highest accuracy obtained was 78.3% on unprocessed images at 80-90 epochs. The authors of [2] found the best performing algorithm to be random forest with a 67% classification accuracy. Their regression approach was more successful with a 95% accuracy using the random forest regressor. In [3], random forest with only morphic features performed the best. The optimal number of PCA features was found to be between 8 and 24 and classification using only morphic features performed better. It was concluded in [4] that normalizing the scale of the galaxy image produces better results with regard to the mean square error value, followed by 256256 scale and then 6464 scale. In [5], 42 images out of 50 matched with Hubble's scheme with the overall agreement being 84%.In [6],Deep Learning has achieved significant results and an huge improvement in visual detection and the recognition.The best performing model was found to be Random forest and Neural networks. A robust deep convolutional neural network architecture for the galaxy morphology classification was developed.In [7],the results obtained here considering two classes are very consistent (OA ≥ 98.7%) and for the three classes problem they are still good, considering the quality of the data (OverAll accuracy~82%).Both Deep and Traditional Machine Learning approaches have over 94.5% OAto classify galaxies in two classes (elliptical and spiral). Considering only two classes separation, 99% of overall accuracy is achieved in average when using our deep learning models, and 82% when using three classes.In [8],The proposed convolutional neural network architecture consists of 8 layers, including one main convolutional layer for feature extraction with 96 filters and two principle fully connected layers for classification. The architecture is trained over 4238 images and achieved a 97.772% testing accuracy.In [9],Model achieves the best classification performance, the overall accuracy on testing set is 95.2083% and the accuracy of the 5 galaxy types are: completely round, 96.6785%; in-between, 94.4238%; cigar-shaped, 58.6207%; edge-on, 94.3590% and spiral, 97.6953% respectively. The average precision, recall, F1 and AUC of the model were 0.9512, 0.9521, 0.9515 and 0.9823.In [10],The Decision tree learning algorithms and fuzzy inferencing systems were applied for galaxy morphology classification where the CART, the C4.5, the Random Forest and fuzzy logic algorithms were studied and reliable classifiers were developed The Random Forest gave the best results.
[13]They considered the human classification as ground truth and achieved 85% performance for 8 features .[12] Comparisions were made between classification schemes for different datasets.For StarGalaxy dataset, from scratch 98%, extracting features from a model pre-trained on ImageNet 93%; extracting features from a model pre-trained on the pretext task 97%; fine-tuning a model pre-trained on ImageNet 99%; fine-tuning a model pre-trained on the pretext task 99%. [15] achieved performance similar to that of human classification.[14] a 93% of correct classification of spiral,elliptical,irregular type.[11]For GZ2 based model different level of accuracy is reached for different question, 98% for Q1,97% for edge on,bar and merger.As of N10 based 96% for strong bar,80 % for weak bars.[17] used three machine learning algorithms- Naive Bayes, rule-induction C4.5 and random forest. Ensemble method called bagging was used here. Random forest yielded more accurate results compared to the other two algorithms that is 91.64% accuracy for three-class case, 54.72% for five-class case, and 48.62% accuracy for the seven-class case. Ensemble method achieved better results than individual classifiers. [20] SVM classifier was trained using 14 galaxies and validated with 3. The classification for part (1)ellipticals and spirals and (2)simple spirals and barred spirals was 100%. [16] used artificial neural network algorithm to classify the galaxies. The neural network behaved as Bayesian classifier. The accuracy was 64 percent when the highest probability was considered and the accuracy was 90 percent when the first or the second choice was considered. [18] used CNN for classification. The accuracy of bent-tailed radio galaxies was 95% and 91% for FRI and 75% for FRII classes.


## Discussions
